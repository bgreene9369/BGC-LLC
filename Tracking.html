<!DOCTYPE html>
 <html>
   <head>
     <meta charset="utf-8" />
	 <meta name="viewport" content="width=device-width"/>	
	 <title>Tracking</title>
	 <link type="text/css" rel="stylesheet" media="screen" href="greene.css" />
	  <link type="text/css" rel="stylesheet" media="print" href="gcprint.css" />
	  <link rel="icon" href="images/favicon.ico" type="image/x-icon">
	  <!--[if lt IE 9]>
      <script src="scripts/semantic.js"></script>
    <![endif]-->
   </head>
     <body>
	  <p id="skipnav"><a href="#main">Skip navigation</a></p> 
	 <div id="box">
	 <h1> 
	 <img src="images/BGC-High-res.png" width="1000" height="180" alt="Bill Greene Consulting, LLC">
	 </h1>
	      <nav id="mainnav">
		     <ul>
			  <li><a href="index.html">Home</a></li>
			  <li><a href="AboutUs.html">About Us</a></li>
			  <li><a href="GreeneBio.html">Bio</a></li>
			  <li><a href="getbill.html">Contact Bill</a></li>
			  <li><a href="references.html">References</a></li>
			  <li><a href="philosophy.html">Philosophy</a></li>
			  <li><a href="Coaching.html">Coaching</a></li>
			  <li><a href="consulting.html">Consulting</a></li>
			  <li><a href="OutMeaPhil.html">Outcome Measurement Philosophy</a></li>
			  <li><a href="Measurement.html">Measurement</a></li>
			  <li><a href="Tracking.html">Tracking</a></li>
			  <li><a href="Reporting.html">Reporting</a></li>
			  <li><a href="Training.html">Training</a></li>
			  <li><a href="Areasserved.html">Areas Served</a></li>
			  <li><a href="Marketing.html">Marketing</a></li>
			  <li><a href="Boarddevelopment.html">Board Development</a></li>
			  <li><a href="Grant.html">Grant Assistance</a></li>
			</ul>  
		 </nav>	 
	  </div>
	  <article class="maintext">
	   <div id="body">
			<h2>Planning Your Outcomes Evaluation -- Step 1: Getting Ready</h2>

				<ul>
				<li>You can very likely draft your own version of most of your outcomes evaluation plan and then have others review your drafts of those sections of the plan. (This "short-cut" approach to outcomes evaluation planning might be questioned by some experts on outcomes -- but then small nonprofits rarely have the resources to fully carry out the comprehensive and detailed steps often recommended by outcomes evaluation resources.)</li>
				<li>Remember that you don’t have to be an expert to start the planning process -- each plan is different -- ultimately, you're the expert at your process and your plan</li>
				<li>Do consider getting a grant to support development of your plan, eg, maybe $3,000 to $5,000, particularly to have evaluation expertise to review your plans and your methods of data collection -- if you can't get this grant, you still can proceed with your plan</li>
				<li>DO tap the many resources available to help you (useful online resources are listed below)</li>
				<li>Now pick one program to evaluate that has a reasonably clear group of clients and clear methods to provide services to them -- in other words, make sure that you have a program to evaluate!</li>
				<li>NOTE: Soon, you should train at least one board member and staff member about outcomes -- consider using this very basic online guide</li>
				</ul>
				<hr />
				
				<a name="anchor178333" ></a>
			<h2>Planning Your Outcomes Evaluation -- Step 2: Choosing Outcomes</h2>

					<h3>Preparation</h3>

					<ul>
					<li>Note that a logic model for your program is depiction of inputs, activities, outputs and outcomes (short-term, intermediate and long-term) regarding your program. Take a look at the information in <a href="http://en.wikipedia.org/wiki/Logic_model" target="_blank" >Introduction to Program Logic Model</a></li>
					<li>Reread the myths listed above – don’t worry about competing the “perfect” logic model – ultimately, you’re the expert here</li>
					</ul>

					<h3>Now Identify Your Outcomes (including short-term, intermediate and long-term)</h3>

					<ul>
					<li>Now fill in a logic model for the program to which you want to apply outcomes-based evaluation -- see <a href="http://managementhelp.org/evaluation/logic-model-guide.htm" >the example logic model and framework</a> -- BUT first read the next several bullets below in this section:</li>
					<li>To identify outcomes, consider: “enhanced …”, “increased …”, “more …”, “new …”, “altered …”, etc.</li>
					<li>Note that it can be quite a challenge to identify outcomes for some types of programs, including those that are preventative (health programs, etc.), developmental (educational, etc.), or "one-time" or anonymous (food shelves, etc.) in nature. In these cases, it's fair to give your best shot to outcomes planning and then learn more as you actually apply your outcomes evaluation plan. Also seek help and ideas about outcomes from other nonprofits that provide services similar to yours. Programs that are remedial in nature (that is, that are geared to address current and observable problems, such as teen delinquency, etc.) are often easier to associate with outcomes.</li>
					<li>Start with short-term outcomes</li>
					<li>Regarding identifying short-term outcomes, think 0-6 months:<br />
					-- Imagine your client in the program or a day after leaving the program<br />
					-- What knowledge and skills do you prefer? Actually see?</li>
					<li>Regarding identifying intermediate outcomes, think 3-9 months: <br />
					-- Imagine your client 3-9 months after leaving the program<br />
					-- What behaviors do you prefer? Actually see?</li>
					<li>Regarding long-term outcomes, think 6-12 months:<br />
					-- Imagine your client 6-12 months after leaving the program<br />
					-- What values, attitudes, status would you prefer to be the fullest extent of benefit for the client? Actually see?</li>
					<li>Now “chain” the short-term, intermediate- and long-term outcomes by applying the following sentence to them:<br />
					-- "if this short-term occurs, then the intermediate occurs, and if this intermediate occurs, then this long-term occurs -- AGAIN, don't worry about getting it perfect -- trust your intuition</li>
					</ul>
					<hr />
				
				<a name="anchor178333" ></a>

			<h2>Planning Your Outcomes Evaluation -- Step 3: Selecting Indicators</h2>

				<h3>Preparation</h3>

				<ul>
				<li>Identify at least one indicator per outcome (note that sometimes indicators are called performance standards)</li>
				<li>When selecting indicators, ask:<br />
				-- What would I see, hear, read about clients that means progress toward the outcome?<br />
				-- Include numbers and percent regarding the client's behavior , eg, "2,000 of the participants (50%) of our participants will quick smoking by the end of the program" and "3,000 of the participants (75%) of our participants will quick smoking one month after the program"<br />
				-- If is your first outcomes plan that you've ever done or the program is just getting started, then don't spend a great deal of time trying to find the perfect numbers and percentages for your indicators</li>
				<li>Fill in your indicators in the <a href="http://managementhelp.org/evaluation/outcomes-framework.htm" >Framework for a Basic Outcomes-Based Evaluation Plan</a>. Also, carry over the outcomes you identified from the <a href="http://managementhelp.org/evaluation/logic-model-guide.htm" >example logic model</a> to the basic evaluation plan.</li>
				</ul>
				<hr />
				
				<a name="anchor178333" ></a>

			<h2>Planning Your Outcomes Evaluation -- Step 4: Planning Data/Information</h2>

				<h3>Preparation</h3>

				<ul>
				<li>Now might be the best time to get some evaluation expertise, for example, a consultant or utilize a local nonprofit service provider to help you review your drafted outcomes and indicators. The expert is also worth their "weight in gold" when reviewing methods to collect data.</li>
				</ul>

				<h3>Get Your Work Reviewed Now By Others</h3>

				<ul>
				<li>If you’ve drafted outcomes and indicators yourself, get them reviewed by:<br />
				-- Board members<br />
				-- Staff<br />
				-- Client in program? Finished with the program?<br />
				-- Evaluation consultant?</li>
				</ul>

				<h3>Identify Data Sources and Methods to Collect Data</h3>

				<ul>
				<li>For each indicator, identify what information you will need to collect/measure to assess that indicator. Consider:<br />
				-- Current program records and data collection<br />
				-- What you see during the program<br />
				-- Ask staff for ideas</li>
				<li>Is it practical to get that data?<br />
				-- What will it cost?<br />
				-- Who will do it?<br />
				-- How can you make the time?</li>
				<li>When to collect data?<br />
				-- Depends on indicator<br />
				-- Consider: before/after program, 6 months after, 12 months after</li>
				<li>Data collection methods:<br />
				-- Questionnaires?<br />
				-- Interviews?<br />
				-- Surveys?<br />
				-- Document review?<br />
				-- Other(s)?</li>
				<li>Get evaluation consultant/expertise?</li>
				<li>Pretest your data collection methods (eg, have a few staff quickly answer the questionnaires to ensure the questions are understandable)</li>
				<li>Write a brief procedure to specify:<br />
				-- What data is collected?<br />
				-- Who collects it?<br />
				-- How they collect it?<br />
				-- When they collect it?<br />
				-- What do they do with it?</li>
				</ul>

				<br /> 
				
				<hr /><p><a name="anchor178047"></a></p>

				<h2>Planning Your Outcomes Evaluation -- Step 5: Piloting/Testing</h2>

					<ul>
					<li>If yours is a small nonprofit, then it's very likely that you don't have nearly the resources to invest in applying your complete outcomes evaluation process in order to test it out.</li>
					<li>In that case, then the first year of applying your outcomes process is the same as piloting your process.</li>
					<li>During the first year, notice problems and improvements, etc.</li>
					<li>Document these in your evaluations plan.</li>
					<li>If something happens to you so that you leave the organization, the organization should not have to completely recreate an outcomes plan. Be sure that write down any suggestions to improve the plan.</li>
					</ul>

				<hr />
				
				<a name="anchor178333" ></a>
				
			<h2>Planning Your Outcomes Evaluation -- Step 6: Analyzing/Reporting</h2>

					<h3>Preparation</h3>

					<ul>
					<li>Strongly consider getting evaluation expertise now to review, not only your methods of data collection mentioned above, but also how you can analyze the data that you collect and how to report results of that analyses.</li>
					<li>Before you analyze your data, <i>always</i> make and retain copies of your data.</li>
					</ul>

					<h3>Analyzing Your Data</h3>

					<ul>
					<li>For dealing with numerical data with numbers, rankings:<br />
					-- Tabulate the information, i.e., add up the ratings, rankings, yes's, no's for each question. <br />
					-- For ratings and rankings, consider computing a mean, or average, for each question. <br />
					-- Consider conveying the range of answers, e.g., 20 people ranked "1", 30 ranked "2", and 20 people ranked "3".</li>
					<li>To analyze comments, etc. (that is, data that is not numerical in nature):<br />
					-- Read through all the data<br />
					-- Organize comments into similar categories, e.g., concerns, suggestions, strengths, etc.<br />
					-- Label the categories or themes, e.g., concerns, suggestions, etc.<br />
					-- Attempt to identify patterns, or associations and causal relationships in the themes</li>
					</ul>
		</div>
	  </article>
	<footer>
		<p id="footer"> 520 James Street    Elkhart, IN 46516    (574) 830-6549</p>
	</footer>
     </body>
</html>